"""
_x, _y 是我们已知的数据, 我们需要根据已知的数据建立模型， 然后训练模型得到我们理想的模型参数
得到了训练好的模型后就可以使用未知的x得到预测值y

分析：
1. 将数据可视化发现数据呈线性分布， 所以可以使用线性模型  y=wx+b
2. 确定损失函数   -- MSE
3. 使用MSE对参数w和b求导， 得到梯度
4. 模型开始训练，使用梯度更新w和b
5. 使用以上的步骤不断的学习，也就是训练轮次
6. 观察损失值，需要将损失数据可视化， 同时我们也可以将拟合的过程进行可视化
"""
import matplotlib.pyplot as plt
import numpy as np
import random

_x = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18,
      0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37,
      0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56,
      0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75,
      0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94,
      0.95, 0.96, 0.97, 0.98, 0.99]

_y = [10.903158923688931, 10.260427407119593, 10.23009698523407, 10.808957429789663, 10.13222141343692,
      10.739843915009573, 10.779543385228177, 10.39319562692106, 10.867506436496374, 10.54003627521104,
      10.721003904071088, 11.279496544232908, 10.9748850111954, 10.429211395509569, 11.33107541276138,
      10.61533867108635, 10.729480289377939, 11.320524927286629, 10.864059902467645, 11.458601395315497,
      11.202174607457332, 11.045846832740496, 11.230382004603323, 10.841003760855399, 11.216082581041976,
      11.667132702921858, 11.748689877085274, 11.567513928895249, 10.910552648263243, 11.2118604304275,
      11.77560455926198, 11.873476711047857, 11.773623509632788, 11.353094248487249, 11.33449070502612,
      11.409140140269084, 11.743357208054634, 11.695392916133818, 11.788223862913945, 11.828418083218418,
      12.17953130893007, 11.93241756279078, 11.506022764554475, 11.709365539174797, 11.778776808767686,
      11.708999378843732, 12.048638713494713, 11.59633100490216, 12.43420665250285, 12.197657818982906,
      11.534208855008803, 12.174011739746918, 11.862006568520991, 12.53129960197658, 12.400685841132757,
      11.982786739354841, 11.976709918944696, 11.89158482413224, 12.641654750097459, 12.096718206814987,
      12.299693846966303, 12.101623678535745, 12.279611075865516, 12.501455395776713, 12.268255426002032,
      12.330409267145127, 12.463424884696932, 12.399977393329756, 12.576298460541528, 12.72933489393335,
      12.37742728304226, 13.041252763556157, 12.337670986294956, 12.879480179817092, 13.187560990720621,
      12.430859362786405, 12.523661532634668, 12.532775473528293, 13.013092048571309, 12.840868384921087,
      13.302498346092555, 12.488170427588303, 13.162403745221493, 12.670444193352674, 13.126131928216612,
      12.920530575593572, 13.429416113943217, 13.499792647635834, 13.119753378294917, 12.971875427030024,
      13.436148582204764, 12.923355132880364, 13.14665703270273, 13.236709486761038, 13.258506990752556,
      13.277559983379899, 13.674777525916692, 13.630316227525892, 13.134274833446025, 13.893578976885745]

# 需要将列表转成ndarry, 方便计算
_x = np.array(_x)
_y = np.array(_y)


# 1. 将数据可视化发现数据呈线性分布， 所以可以使用线性模型  y=wx+b
def model(w, x, b):
    return w * x + b


# 2. 确定损失函数   -- MSE
def mse_loss(true_y, pred_y):
    # return np.sum((pred_y - true_y) ** 2) / len(true_y)
    return np.mean((pred_y - true_y) ** 2)


# 3. 使用MSE对参数w和b求导， 得到梯度
def get_grad(x, pred_y, true_y):
    # grad_w = 2 * 1 / len(x) * sum((pred_y - true_y) * x)
    grad_w = 2 * np.mean((pred_y - true_y) * x)
    # grad_b = 2 / len(x) * sum(pred_y - true_y)
    grad_b = 2 * np.mean(pred_y - true_y)
    return grad_w, grad_b


# 4. 模型开始训练，使用梯度更新w和b
def train(epoches, learn_rate):
    # 初始化w和b
    # w和b的值第一次是我们初始化的， 从第二次开始都是模型学习过程中自动调整的
    w = random.random()
    b = random.random()
    # 每训练一轮进行一次可视化展示
    ax01 = plt.subplot(211)
    ax02 = plt.subplot(212)
    # 定义列表存储每一轮的损失值 --- 为了可视化显示
    loss_list = []

    # 5. 模型需要不断的学习，也就是训练轮次
    for epoch in range(epoches):
        # 通过模型得到预测值
        pred_y = model(w, _x, b)
        # 使用预测值和真实值计算损失
        loss = mse_loss(_y, pred_y)
        loss_list.append(loss)
        # 使用mse对w和b求导，得到梯度
        grad_w, grad_b = get_grad(_x, pred_y, _y)
        # 使用梯度更新参数
        w -= learn_rate * grad_w
        b -= learn_rate * grad_b

        # 清除坐标轴区域内容
        ax01.cla()
        # 使用散点图显示数据
        ax01.scatter(_x, _y)
        # 绘制模型的折线图， 也就是一条直线, 使用动画显示拟合的过程
        ax01.plot(_x, pred_y, color="red", label=f"y={w:.4f}x+{b:.4f}")
        ax01.legend()

        # 绘制损失值的曲线图
        ax02.cla()
        # 绘制损失的折线图
        # x应该是轮次， 但是这里省略了就会使用loss_list的索引值， 索引值正好就是轮次
        ax02.plot(loss_list, color="red", label=f"epoch:{epoch}, loss:{loss:.4f}")
        ax02.legend()

        plt.pause(0.1)
    plt.show()


if __name__ == '__main__':
    train(1000, 0.1)
